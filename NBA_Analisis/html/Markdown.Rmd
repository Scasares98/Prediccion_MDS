---
title: "Modelo Predicción - NBA"
author: "Sergio Casares Fernandez"
date: "28/10/2020"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

# __Introducción al trabajo:__
El próximo documento, se tratará de realizar un modelo predictivo de un dataset acerca de los salarios de los jugadores de la NBA junto a otra 29 variables. La finalidad será la de poder predecir y explicar cuáles son los factores principales que influyen en el salario de los jugadores.

El dataset consta, tras eliminar los valores nulos, de 485 observaciones y 28 variables, las cuales se resumirán en las siguientes líneas del documento:

1:Player           Nombre del jugador.

2:Salary          Salario del jugador.

3:NBA_Country      Nacionalidad del jugador.

4:NBA_DraftNumber  Número del draft.

5:Age              Edad del jugador.

6:Tm              Abreviatura del equipo

7:G               Partidos jugados

8:MP              Minutos jugados

9:PER             Eficiencia de jugador

10:TS%            Porcentaje de tiro

11:3PAr           % de triples

12:FTr             % de tiros libres

13:ORB%           % Rebotes Ofensivos ganados

14:DRB%           % Rebotes defensivos ganados

15:TRB%            % Rebotes totales

16:AST%           % Asistencia

17:STL%           % Robos

18:BLK%            % Bloqueos

19:TOV%           % Robo previo a tiro

20:USG%           % de participacion en jugadas

21:OWS            Acciones en ataque acertadas

22:DWS             Acciones defensivas acertadas

23:WS             Victorias contribuidas

24:WS/48           Ratio de contribución por partido

25:OBPM          +/- rendimiento respecto al equipo (cada 100 jugadas en ataque)

26:DBPM            +/- rendimiento respecto al equipo (cada 100 jugadas en defensa)

27:BPM             +/- rendimiento respecto al equipo (cada 100 posesiones generales)

28:VORP            Valor respecto a jugador involucrado en el cambio


Para poder comenzar a trabajar con el modelo, debemos instalar las librerías necesarias e importar el archivo donde se encuentra la información

```{r cars}
library(tidyverse)
library(fBasics)
library(car)
library(dplyr)
library(ggplot2)
library(knitr)
library(MASS)
library(corrplot)
library(PerformanceAnalytics)
library(gvlma)

nba <- read_delim("nba_2.csv", ";", escape_double = FALSE, 
                    trim_ws = TRUE)

attach(nba)
head(nba)
summary(nba)
names(nba)
```

__Limpieza de datos:__

A continuación, vamos a eliminar aquellas filas donde aparezcan valores nulos. Además, vamos a transformar las variables de Tm (Teams) y Country (Países) de cualitativa a cuantitativa por medio de la función __match.__

```{r pressure, echo=FALSE}
nba <- na.omit(nba)
unique(nba$Tm)
levels <- c('HOU', 'GSW', 'SAC', 'CHI', 'POR',
            'DAL', 'BOS', 'MEM', 'DEN',
            'TOT', 'LAC', 'ORL', 'MIA',
            'IND', 'LAL', 'MIN', 'PHO',
            'ATL', 'CLE', 'NYK', 'CHO',
            'MIL', 'SAS', 'UTA', 'NOP',
            'WAS', 'PHI', 'BRK', 'OKC',
            'DET', 'TOR')

nba$Team <- match(nba$Tm, levels)

#Convertir la variable NBA_Country (Países) de cualitativa a Cuantitativa
unique(nba$NBA_Country)
levels <- c('China', 'Georgia', 'USA', 'Canada', 'Spain',
            'France', 'Czech Republic', 'Russia', 'South Sudan',
            'Switzerland', 'New Zealand', 'Haiti', 'Democratic Re_',
            'Tunisia', 'Brazil', 'Germany', 'Australia',
            'Cameroon', 'Israel', 'Turkey', 'United Kingdo...',
            'Montenegro', 'Serbia', 'Argentina', 'Bosnia',
            'Lithuania', 'Croatia', 'Italy', 'Poland',
            'Dominican Rep...', 'Finland', 'Latvia', 'Bosnia & Herz...',
            'Sweden', 'Ukraine', 'Austria', 'Puerto Rico',
            'Senegal', 'Slovenia', 'Greece', 'Democratic Re...',
            'Mali', 'Bahamas', 'Egypt')
nba$Pais <- match(nba$NBA_Country, levels)
```
## __Modelo General:__

Una vez convertidas todas las variables a numéricas, vamos a realizar, simplemente de manera explicativa, el análisis del modelo donde la variable __salario__ sea explicada por medio de la combinación lineal de las otras 27 variables restantes.

A continuación de la descripción del model, se proyectarán tres gráficas que nos explicarán diferentes características acerca de este modelo:

__Residual vs Fitted graph:__ es una gráfica donde se reflejan los residuos en el eje Y los valores ajustados en el eje X. Con esta gráfica se tratará de detectar la no linearidad, errores de varianza y outliers.

__Normal Q Q:__ es un método gráfico para el diagnóstico de diferencias entre la distribución de probabilidad de una población de la que se ha extraído una muestra aleatoria y una distribución usada para la comparación.

__Scale Location:__ esta gráfica enseña si los residuos están distribuidos de manera equitativa a lo lardo de los rangos de predicción. Con esta gráfica se puede comprobar la asunción de igual varianza (homocedasticidad).


```{r}
model <- lm(log(Salary, base = 10) ~ NBA_DraftNumber + Age + G + MP + PER + PAr + FTr + ORB + DRB + TRB +
              AST + STL + BLK + TOV + USG + OWS + DWS + WS + WS_1 + OBPM + DBPM + BPM + VORP + Team + Pais, data = nba)
model

plot(model)

summary(model)

```

### Conclusión Modelo General:

Tras realizar la ilustración de nuestro modelo general, se puede comprobar, por medio de la función __summary__ la significatividad que tienen ciertas variables en nuestro modelo como NBA_DraftNumber, G, Age y MP con un nivel de significatividad del 0.01; por otra parte, la variable PER cuenta con un nivel de significatividad del 0.05 y USG cuenta con un nivel de significatividad del 0.10.

Respecto a las gráficas, en la gráfica __"Normal Q Q"__, se puede observar cómo los valores más alejados de la media tienden a tener una mayor dispersión respecto de la media. 
En la gráfica __"Scale-Location"__ se puede observar como los valores se concentrar, aunque no de una manera evidente, en los valores centrales y su densidad tiende a disminuir a medida que se alejan del centro, lo que nos podría indicar una cierta heterocedasticidad.
En la gráfica __"Residual vs Leverage"__ podemos comprobar cómo hay ciertos valores que se alejan de los valores normales del modelo (outliers).

Por último, decir que R^2, el cual representa la bondad de ajuste del modelo, es de 0.5522, por lo que la roporción de la varianza total de la variable explicada por la regresión es del 55,22% sobre el total del modelo.

# Elección del modelo óptimo:

Varias son las maneras en las que se puede optimizar el modelo, pero para nuestro dataset se ha pensado que el Modelo del Critero de Informacion de Akaike (AIC) es el más óptimo para realizar nuestra elección.

El odelo del Critero de Informacion de Akaike (AIC), este modelo se caracteriza por una formulación simple y una fácil aplicación: una vez calculado el AIC para cada modelo se elige aquel cuyo AIC es mínimo. La solución dada por Akaike es elegir como función depérdida (o criterio de especificación) el mínimo del criterio de información AIC.

Se basa en la medida de información de Kullback-Leibler (1951), la cual permite interpretar la distancia entre dos distribuciones (en nuestro caso, la observada a partir de la muestra y la teórica) a partir de la log-verosimilitud de un modelo. 

AIC = −2 ln(maxima verosimilitud) + 2(nº parametros independientemente ajustados)

```{r}
stepAIC(model, direction = 'both')

primer_filtro <- lm(formula = Salary ~ NBA_DraftNumber + Age + G + MP + PER + 
               PAr + ORB + TRB + USG + WS + OBPM + Team, data = nba)
summary(primer_filtro)

```


La función __stepAIC__ realiza una serie de combinaciones de modelos para elegir la más óptima, es decir, aquella que presente menor error estandar de los residuos).
Para este primer cribado, esta técnica nos ha seleccionado un modelo formado por 12 variables y con un error estandar de los residuos de 5051000, pero que cuenta con un R^2 de 0.5455, por lo que hemos conseguido simplificar nuestro modelo obteniendo prácticamente la misma capacidad predictiva.

### Análisis de multicolinealidad

La multicolinealidad se puede deber a una correlación alta entre las diferentes variables del modelo, por eso, a través del modelo VIF (Variance Inflation Factors), vamos a obtener la inflación de la varianza para modelos lienales con el fin de dilucidar qué variables osn menos representatitas y deben ser apartadas del modelo.

Trataremos de eliminar aquellas variables que presentar un valor Raiz(vif) que sea superior a 2 con el fin de apartar del modelo aquellas variables poco representativas.

```{r}
vif(primer_filtro) 
sqrt(vif(primer_filtro)) > 2

modelo_filtro_vif <- lm(formula = Salary ~ NBA_DraftNumber + Age + G + 
               PAr + ORB + TRB + USG + WS + OBPM + Team, data = nba)
summary(modelo_filtro_vif)
```

Con este filtro hemos conseguido eliminar la multicolinealidad del modelo.

## Validación:

Para poder validar el modelo, utilizaremos el paquete __GVLMA__ (Global Validation of Linear Model Assumptions), la cual se encargará de realizar asunciones de modelos lineales, además de test direccionales diseñados para detectar skewness, kurtosis y heterocedasticidad.


```{r}
val_modelo <- gvlma(modelo_filtro_vif)
summary(val_modelo)
```

El resultado obtenido tras esta validación no es el deseado a la hora de poder validar el modelo, ya que la única asunción que se puede aceptar es el de la Heterocedasticidad. Este modelo presenta Kurtosis, Skewness y Link Function aunque cuente con un R^2 de 0.4991.








